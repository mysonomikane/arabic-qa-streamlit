# ğŸ“š Rapport de Projet NLP
## SystÃ¨me de Question-RÃ©ponse en Arabe basÃ© sur Wikipedia

---

## ğŸ“‹ Informations GÃ©nÃ©rales

| Ã‰lÃ©ment | DÃ©tail |
|---------|--------|
| **Projet** | SystÃ¨me RAG de Question-RÃ©ponse en Arabe |
| **Auteur** | sonomikane |
| **Date** | Janvier 2026 |
| **ModÃ¨le HuggingFace** | [sonomikane/arabert-qa-arabic-wikipedia](https://huggingface.co/sonomikane/arabert-qa-arabic-wikipedia) |
| **Application Streamlit** | [GitHub Repository](https://github.com/mysonomikane/arabic-qa-streamlit) |

---

## 1. ğŸ¯ Objectif du Projet

DÃ©velopper un **assistant intelligent** capable de rÃ©pondre aux questions en arabe en utilisant Wikipedia arabe comme base de connaissances.

### Architecture RAG (Retrieval-Augmented Generation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Question      â”‚â”€â”€â”€â–¶â”‚  ğŸ” RETRIEVAL        â”‚â”€â”€â”€â–¶â”‚  ğŸ“š Wikipedia   â”‚
â”‚   utilisateur   â”‚    â”‚  Recherche Wikipedia â”‚    â”‚  Arabe          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Contexte pertinent  â”‚
                       â”‚  (articles trouvÃ©s)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“ RÃ©ponse    â”‚â—€â”€â”€â”€â”‚  ğŸ¤– GENERATION       â”‚
â”‚   extraite      â”‚    â”‚  AraBERT QA Model    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. ğŸ¤– ModÃ¨le de Base

### AraBERT-v2

| CaractÃ©ristique | Valeur |
|-----------------|--------|
| **Nom** | `aubmindlab/bert-base-arabertv2` |
| **Type** | BERT prÃ©-entraÃ®nÃ© pour l'arabe |
| **ParamÃ¨tres** | ~135 millions |
| **Vocabulaire** | 64,000 tokens |
| **CrÃ©ateur** | AUB MIND Lab |

---

## 3. ğŸ“Š Datasets d'EntraÃ®nement

### Datasets UtilisÃ©s

| Dataset | Type | Taille Train | Taille Val |
|---------|------|--------------|------------|
| **TyDi QA Arabic** | Question-RÃ©ponse | ~14,000 | ~1,500 |
| **ARCD** | Arabic Reading Comprehension | ~2,500 | ~700 |
| **XQuAD Arabic** | Cross-lingual QA | - | ~1,100 |

### Total aprÃ¨s preprocessing

| Split | Nombre d'exemples |
|-------|-------------------|
| **Train** | 17,337 |
| **Validation** | 2,963 |

---

## 4. âš™ï¸ Configuration d'EntraÃ®nement

### HyperparamÃ¨tres

| ParamÃ¨tre | Valeur |
|-----------|--------|
| **Epochs** | 3 |
| **Learning Rate** | 3e-5 |
| **Batch Size (Train)** | 16 |
| **Batch Size (Eval)** | 32 |
| **Max Sequence Length** | 384 |
| **Stride** | 128 |
| **Warmup Ratio** | 0.1 |
| **Weight Decay** | 0.01 |
| **FP16** | Oui (Mixed Precision) |

### Environnement

| Ã‰lÃ©ment | SpÃ©cification |
|---------|---------------|
| **Plateforme** | Google Colab |
| **GPU** | Tesla T4 (16 GB) |
| **Temps d'entraÃ®nement** | ~25.5 minutes |

---

## 5. ğŸ“ˆ RÃ©sultats

### MÃ©triques d'Ã‰valuation

| MÃ©trique | Score |
|----------|-------|
| **F1-Score** | **54.36%** |
| **Exact Match (EM)** | **32.80%** |

### InterprÃ©tation

- **F1-Score de 54.36%** : Le modÃ¨le trouve une correspondance partielle correcte dans plus de la moitiÃ© des cas
- **Exact Match de 32.80%** : Le modÃ¨le trouve la rÃ©ponse exacte dans environ 1/3 des cas
- Ces rÃ©sultats sont dans la moyenne pour un modÃ¨le QA en arabe sur des donnÃ©es rÃ©elles

### Comparaison avec l'Ã©tat de l'art

| ModÃ¨le | F1-Score (TyDi QA Arabic) |
|--------|---------------------------|
| mBERT | ~50% |
| XLM-RoBERTa | ~55% |
| **Notre modÃ¨le** | **54.36%** |
| AraELECTRA | ~60% |

---

## 6. ğŸš€ ModÃ¨le Fine-tunÃ©

### Publication sur Hugging Face Hub

| Ã‰lÃ©ment | Valeur |
|---------|--------|
| **Repository** | `sonomikane/arabert-qa-arabic-wikipedia` |
| **URL** | https://huggingface.co/sonomikane/arabert-qa-arabic-wikipedia |
| **TÃ¢che** | Question Answering |
| **Langue** | Arabe (ar) |

### Utilisation

```python
from transformers import pipeline

# Charger le modÃ¨le
qa_pipeline = pipeline(
    "question-answering",
    model="sonomikane/arabert-qa-arabic-wikipedia",
    tokenizer="sonomikane/arabert-qa-arabic-wikipedia"
)

# Poser une question
result = qa_pipeline(
    question="Ù…Ø§ Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ",
    context="Ù…ØµØ± Ø¯ÙˆÙ„Ø© Ø¹Ø±Ø¨ÙŠØ© ØªÙ‚Ø¹ ÙÙŠ Ø´Ù…Ø§Ù„ Ø£ÙØ±ÙŠÙ‚ÙŠØ§. Ø¹Ø§ØµÙ…ØªÙ‡Ø§ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©."
)

print(result)
# {'answer': 'Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©', 'score': 0.95, 'start': 42, 'end': 49}
```

---

## 7. ğŸŒ Application Streamlit

### FonctionnalitÃ©s

1. **Recherche automatique** dans Wikipedia arabe (composant RETRIEVAL)
2. **Extraction de rÃ©ponses** avec le modÃ¨le fine-tunÃ© (composant GENERATION)
3. **Interface bilingue** arabe/franÃ§ais
4. **Affichage des sources** Wikipedia
5. **Score de confiance** pour chaque rÃ©ponse

### DÃ©ploiement

| Plateforme | URL |
|------------|-----|
| **GitHub** | https://github.com/mysonomikane/arabic-qa-streamlit |
| **Streamlit Cloud** | DÃ©ploiement automatique depuis GitHub |

### Technologies UtilisÃ©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| Streamlit | 1.29.0 | Interface web |
| Transformers | 4.36.0 | ModÃ¨le QA |
| PyTorch | Latest | Backend ML |
| Requests | Latest | API Wikipedia |

### Architecture de l'Application

```
streamlit_app/
â”œâ”€â”€ app.py              # Application principale
â”œâ”€â”€ requirements.txt    # DÃ©pendances
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml     # Configuration Streamlit
```

---

## 8. ğŸ“ Structure du Projet

```
nlp/
â”œâ”€â”€ projet_NLP_WIKI.ipynb      # Notebook d'entraÃ®nement (Colab)
â”œâ”€â”€ test_model.py              # Script de test
â”œâ”€â”€ RAPPORT_PROJET_NLP.md      # Ce rapport
â””â”€â”€ streamlit_app/             # Application web
    â”œâ”€â”€ app.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ .streamlit/
        â””â”€â”€ config.toml
```

---

## 9. ğŸ”„ Pipeline Complet

### Ã‰tape 1 : PrÃ©paration des donnÃ©es
- Chargement de TyDi QA, ARCD, XQuAD
- Filtrage des exemples avec rÃ©ponses
- Tokenization avec AraBERT tokenizer
- Gestion des positions start/end

### Ã‰tape 2 : Fine-tuning
- Chargement du modÃ¨le AraBERT-v2
- EntraÃ®nement sur GPU (Tesla T4)
- 3 epochs avec early stopping
- Sauvegarde du meilleur modÃ¨le

### Ã‰tape 3 : Ã‰valuation
- Calcul du F1-Score et Exact Match
- Validation sur 3 datasets

### Ã‰tape 4 : Publication
- Upload sur Hugging Face Hub
- Documentation du modÃ¨le

### Ã‰tape 5 : DÃ©ploiement
- CrÃ©ation de l'application Streamlit
- IntÃ©gration avec Wikipedia API
- DÃ©ploiement sur Streamlit Cloud

---

## 10. ğŸ“ Conclusion

### Objectifs Atteints

âœ… ModÃ¨le QA fine-tunÃ© sur donnÃ©es arabes  
âœ… F1-Score de 54.36% (objectif "rÃ©sultat moyen" atteint)  
âœ… Publication sur Hugging Face Hub  
âœ… Application web avec recherche Wikipedia  
âœ… SystÃ¨me RAG fonctionnel  

### AmÃ©liorations Possibles

1. **Plus d'epochs** : EntraÃ®ner sur 5-10 epochs pour de meilleurs rÃ©sultats
2. **Data Augmentation** : Ajouter plus de donnÃ©es d'entraÃ®nement
3. **ModÃ¨le plus grand** : Utiliser AraBERT-large au lieu de base
4. **Index local** : CrÃ©er un index FAISS de Wikipedia pour une recherche plus rapide
5. **Caching** : Mettre en cache les rÃ©sultats Wikipedia

---

## 11. ğŸ“š RÃ©fÃ©rences

- [AraBERT Paper](https://arxiv.org/abs/2003.00104)
- [TyDi QA Dataset](https://ai.google.com/research/tydiqa)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Streamlit Documentation](https://docs.streamlit.io)
- [Wikipedia API](https://www.mediawiki.org/wiki/API:Main_page)

---

## 12. ğŸ”— Liens du Projet

| Ressource | Lien |
|-----------|------|
| **ModÃ¨le HuggingFace** | https://huggingface.co/sonomikane/arabert-qa-arabic-wikipedia |
| **Code GitHub** | https://github.com/mysonomikane/arabic-qa-streamlit |
| **Application Live** | Streamlit Cloud (auto-dÃ©ployÃ©e) |
| **AraBERT Original** | https://huggingface.co/aubmindlab/bert-base-arabertv2 |

---

*Rapport gÃ©nÃ©rÃ© le 11 Janvier 2026*
